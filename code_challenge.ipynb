{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-21T00:29:10.293525Z",
     "start_time": "2025-11-21T00:29:10.288335Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    roc_auc_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    precision_score,\n",
    "    recall_score\n",
    ")\n",
    "\n",
    "import warnings\n",
    "from sklearn.exceptions import UndefinedMetricWarning\n",
    "warnings.filterwarnings(\"ignore\", category=UndefinedMetricWarning)\n"
   ],
   "id": "719f5de5aef4b2b",
   "outputs": [],
   "execution_count": 35
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Part 1: Baseline Evaluation",
   "id": "3b07f7fd6352f758"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-21T00:07:11.273722Z",
     "start_time": "2025-11-21T00:07:11.263065Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load data\n",
    "train = pd.read_csv('data/ecommerce_returns_train.csv')\n",
    "test = pd.read_csv('data/ecommerce_returns_test.csv')"
   ],
   "id": "c572a67631b6de68",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-21T00:13:45.765290Z",
     "start_time": "2025-11-21T00:13:45.758816Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def preprocess(df):\n",
    "    \"\"\"Exact replication of baseline_model.py preprocessing\"\"\"\n",
    "    df_processed = df.copy()\n",
    "\n",
    "    # Encode categorical: product_category\n",
    "    # CRITICAL WEAKNESS: LabelEncoder implies ordinality (0 < 1 < 2) for nominal data\n",
    "    le_category = LabelEncoder()\n",
    "    df_processed['product_category_encoded'] = le_category.fit_transform(\n",
    "        df_processed['product_category']\n",
    "    )\n",
    "\n",
    "    # Handle missing sizes\n",
    "    # WEAKNESS: Imputing mode for Electronics/Home Decor creates noise\n",
    "    if df_processed['size_purchased'].notna().any():\n",
    "        most_common_size = df_processed['size_purchased'].mode()[0]\n",
    "        df_processed['size_purchased'] = df_processed['size_purchased'].fillna(most_common_size)\n",
    "\n",
    "\n",
    "        le_size = LabelEncoder()\n",
    "        df_processed['size_encoded'] = le_size.fit_transform(\n",
    "            df_processed['size_purchased']\n",
    "        )\n",
    "\n",
    "    feature_cols = [\n",
    "        'customer_age', 'customer_tenure_days', 'product_category_encoded',\n",
    "        'product_price', 'days_since_last_purchase', 'previous_returns',\n",
    "        'product_rating', 'size_encoded', 'discount_applied'\n",
    "    ]\n",
    "\n",
    "    X = df_processed[feature_cols]\n",
    "    y = df_processed['is_return']\n",
    "\n",
    "    return X, y"
   ],
   "id": "a350e1240deb3e1b",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-21T00:18:21.877144Z",
     "start_time": "2025-11-21T00:18:21.856851Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Prepare data\n",
    "X_train, y_train = preprocess(train)\n",
    "X_test, y_test = preprocess(test)\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Train baseline model\n",
    "baseline_model = LogisticRegression(random_state=42, max_iter=1000)\n",
    "baseline_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred = baseline_model.predict(X_test_scaled)\n",
    "y_prob = baseline_model.predict_proba(X_test_scaled)[:, 1]\n"
   ],
   "id": "bf082deaa444e67f",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-21T00:21:17.819357Z",
     "start_time": "2025-11-21T00:21:17.808745Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Basic evaluation\n",
    "print(\"Baseline Model Performance\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n"
   ],
   "id": "95eb8cf643a96643",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Model Performance\n",
      "==================================================\n",
      "Accuracy: 0.7475\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      1.00      0.86      1495\n",
      "           1       0.00      0.00      0.00       505\n",
      "\n",
      "    accuracy                           0.75      2000\n",
      "   macro avg       0.37      0.50      0.43      2000\n",
      "weighted avg       0.56      0.75      0.64      2000\n",
      "\n"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-21T00:15:08.193468Z",
     "start_time": "2025-11-21T00:15:08.186591Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Save artifacts\n",
    "joblib.dump(baseline_model, 'baseline_model.pkl')\n",
    "joblib.dump(scaler, 'scaler.pkl')"
   ],
   "id": "c890b72eedbf7fb6",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['scaler.pkl']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## COMPREHENSIVE EVALUATION",
   "id": "b90d85d7c98d8cf0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-21T00:31:35.788708Z",
     "start_time": "2025-11-21T00:31:35.766172Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"1. Overall Metrics\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
    "print(f\"ROC-AUC: {roc_auc_score(y_test, y_prob):.4f}\")\n",
    "print(f\"Precision (Class 1): {precision_score(y_test, y_pred, zero_division=0):.4f}\")\n",
    "print(f\"Recall (Class 1): {recall_score(y_test, y_pred, zero_division=0):.4f}\")\n",
    "print(f\"Macro F1 Score: {f1_score(y_test, y_pred, average='macro'):.4f}\")\n",
    "print(\"\\nClass 1 (Returned):\")\n",
    "print(f\"Class 1 Recall:    {recall_score(y_test, y_pred, pos_label=1):.4f} (Crucial for catching returns)\")\n",
    "print(f\"Class 1 Precision: {precision_score(y_test, y_pred, pos_label=1):.4f} (Crucial for intervention cost)\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred, zero_division=0))"
   ],
   "id": "9f6e3448e5acecf4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Overall Metrics\n",
      "Accuracy: 0.7475\n",
      "ROC-AUC: 0.5622\n",
      "Precision (Class 1): 0.0000\n",
      "Recall (Class 1): 0.0000\n",
      "Macro F1 Score: 0.4278\n",
      "\n",
      "Class 1 (Returned):\n",
      "Class 1 Recall:    0.0000 (Crucial for catching returns)\n",
      "Class 1 Precision: 0.0000 (Crucial for intervention cost)\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      1.00      0.86      1495\n",
      "           1       0.00      0.00      0.00       505\n",
      "\n",
      "    accuracy                           0.75      2000\n",
      "   macro avg       0.37      0.50      0.43      2000\n",
      "weighted avg       0.56      0.75      0.64      2000\n",
      "\n"
     ]
    }
   ],
   "execution_count": 39
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-21T00:21:57.258541Z",
     "start_time": "2025-11-21T00:21:57.252653Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"2. Confusion Matrix Interpretation\")\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "\n",
    "print(f\"True Negatives (Kept & Predicted Kept): {tn}\")\n",
    "print(f\"False Positives (Kept but Predicted Return): {fp} (Cost: ${fp} * 3 = ${fp*3})\")\n",
    "print(f\"False Negatives (Returned but Predicted Kept): {fn} (Cost: ${fn} * 18 = ${fn*18})\")\n",
    "print(f\"True Positives (Returned & Predicted Return): {tp}\")\n"
   ],
   "id": "7616ff745c573109",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2. Confusion Matrix Interpretation\n",
      "True Negatives (Kept & Predicted Kept): 1495\n",
      "False Positives (Kept but Predicted Return): 0 (Cost: $0 * 3 = $0)\n",
      "False Negatives (Returned but Predicted Kept): 505 (Cost: $505 * 18 = $9090)\n",
      "True Positives (Returned & Predicted Return): 0\n"
     ]
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-21T00:24:24.951653Z",
     "start_time": "2025-11-21T00:24:24.925244Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"3. Performance by Product Category\")\n",
    "# Merge predictions back to test set for segmentation\n",
    "test_results = test.copy()\n",
    "test_results['y_true'] = y_test\n",
    "test_results['y_pred'] = y_pred\n",
    "\n",
    "category_metrics = test_results.groupby('product_category').agg({\n",
    "    'y_true': [\n",
    "        ('Accuracy', lambda x: accuracy_score(x, test_results.loc[x.index, 'y_pred'])),\n",
    "        ('Recall (Catch Rate)', lambda x: recall_score(x, test_results.loc[x.index, 'y_pred'], zero_division=0)),\n",
    "        ('Precision', lambda x: precision_score(x, test_results.loc[x.index, 'y_pred'], zero_division=0)),\n",
    "        ('Count', 'count')\n",
    "    ]\n",
    "}).droplevel(0, axis=1).reset_index()\n",
    "\n",
    "print(category_metrics)"
   ],
   "id": "d1e1dabd5f6f8187",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3. Performance by Product Category\n",
      "  product_category  Accuracy  Recall (Catch Rate)  Precision  Count\n",
      "0      Electronics  0.828666                  0.0        0.0    607\n",
      "1          Fashion  0.686594                  0.0        0.0   1104\n",
      "2       Home_Decor  0.809689                  0.0        0.0    289\n"
     ]
    }
   ],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-21T00:25:21.629539Z",
     "start_time": "2025-11-21T00:25:21.625532Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"4. Business Financial Check\")\n",
    "# Baseline Cost (No Model): Total Returns * $18\n",
    "baseline_cost = (tp + fn) * 18\n",
    "# Model Cost: (Intervention Cost) + (Unprevented Returns)\n",
    "# Note: Intervention is applied to (TP + FP). Success rate is 35% on TPs.\n",
    "intervention_cost = (tp + fp) * 3\n",
    "unprevented_return_cost = fn * 18 + (tp * (1 - 0.35) * 18)\n",
    "model_total_cost = intervention_cost + unprevented_return_cost\n",
    "\n",
    "print(f\"Cost without Model: ${baseline_cost:,.2f}\")\n",
    "print(f\"Cost with Baseline Model: ${model_total_cost:,.2f}\")\n",
    "print(f\"Net Profit/Loss: ${baseline_cost - model_total_cost:,.2f}\")"
   ],
   "id": "a1182530f3b013c7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4. Business Financial Check\n",
      "Cost without Model: $9,090.00\n",
      "Cost with Baseline Model: $9,090.00\n",
      "Net Profit/Loss: $0.00\n"
     ]
    }
   ],
   "execution_count": 34
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Evaluation Findings\n",
    "\n",
    "The baseline model has converged into a \"Majority Class Classifier\" (or a \"Null Classifier\"). Because approximately 75% of the training data consists of non-returns, the model has learned that the safest way to minimize error (and maximize accuracy) is to simply predict \"No Return\" (Class 0) for every single order.\n",
    "The model generates zero savings. It is financially equivalent to having no model at all.\n",
    "\n",
    "1. Key Metrics & Justification\n",
    "- Recall: Total Failure. This measures how many actual returns the model catches. If Recall is low, the model is failing its primary purpose, preventing returns.\n",
    "- Precision: Undefined/Zero. Since the model never predicted a return, precision is technically undefined. That's spent 0 on interventions, but also saved 0.\n",
    "- ROC-AUC: Near Random. A score of 0.5 is random guessing. Indicates that even if we lowered the decision threshold, the model has almost no ability to distinguish between a returner and a keeper.\n",
    "2. Confusion Matrix Interpretation:\n",
    "- True Negatives (1495): The model correctly ignored all customers who kept their items.\n",
    "- False Negatives (505): The model missed 100% of the returns. This resulted in 9,090 in return costs that went completely unaddressed.\n",
    "- True Positives (0): Not a single intervention was triggered.\n",
    "3. Performance by Product Category:\n",
    "- The variation in accuracy across categories is not due to model intelligence, but due to the underlying return rates of those categories:\n",
    "- Electronics (82.8% Accuracy): This category likely has a lower return rate around 17%, so guessing \"0\" works better here by luck.\n",
    "- Fashion (68.6% Accuracy): This category has a higher return rate around 31%, so the \"guess 0\" strategy fails more often here.\n",
    "- The model is equally blind across all categories; it is not picking up on category-specific signals (like sizing in Fashion).\n",
    "4. Business Financial Check:\n",
    "- Baseline Cost (No Model): 9,090.00 (505 returns * 18)\n",
    "- Model Cost: 9,090.00(0 intervention + 9,090 unprevented returns)\n",
    "- Net ROI: $0.00\n",
    "- The model generates zero savings. It is financially equivalent to having no model at all.\n",
    "5. Root Causes & Weakness Identification:\n",
    "- Class Imbalance Bias: The Logistic Regression default threshold is 0.5. Since the probability of a return rarely crosses 50% for any given customer in this dataset, the model never pulls the trigger.\n",
    "- The \"Prior\" Probability: In your dataset, only about 25% of orders are returns (505 out of 2000). Without looking at any specific features, the \"base\" probability of any random order being a return is 0.25.\n",
    "- Weak Signal: The ROC-AUC of 0.56 suggests that the current features (Age, Price, etc.) in their current format (linear scaling, label encoding) provide very little signal to separate the classes.\n",
    "- Improper Metric Optimization: The model optimized for standard accuracy (log-loss) rather than a cost-sensitive metric that penalizes missing a return (False Negative) more than a false alarm.\n",
    "\n",
    "\n",
    "The baseline is unfit for production. The improved solution must address the class imbalance and use a model capable of finding non-linear patterns to improve the ROC-AUC score before optimization can even begin."
   ],
   "id": "e327ac3d5fc0e4ba"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Part 2: Business-Aligned Metrics",
   "id": "aa5f8c069c934045"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "1. Success means the model consistently generates positive net financial savings by accurately identifying high-return-risk orders where intervention yields more benefit than cost. In practice, this requires high precision on high-risk orders, strong recall among costliest potential returns, and intervention decisions based on an ROI-optimized probability threshold.\n",
    "2. Recommended Metrics:\n",
    "- Net Savings ($): The estimated dollar amount saved after subtracting intervention costs and remaining return costs.\n",
    "- Precision (Class 1): The Critical Guardrail. Intervening on an order costs $3, and a successful intervention reduces the return probability by 35%, yielding an expected benefit of 0.35×18=6.30, the net financial gain of a True Positive is 6.30−3=3.30. A False Positive, however, costs 3 with no savings, our \"Breakeven Precision\" is very high 3.00/(3.00+3.30). precision is the primary performance constraint. The model must reliably identify only high-risk orders before we care about how many it captures. Precision ensures each intervention makes money.\n",
    "- Recall (Class 1): Secondary to precision. Once we establish a profitable precision tier, we maximize recall to scale the savings. Recall determines how much total money we can make."
   ],
   "id": "11aa00e62a728a34"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-21T01:03:07.084222Z",
     "start_time": "2025-11-21T01:03:07.075629Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def preprocess_fixed(df):\n",
    "    df_processed = df.copy()\n",
    "    le_category = LabelEncoder()\n",
    "    df_processed['product_category_encoded'] = le_category.fit_transform(df_processed['product_category'])\n",
    "\n",
    "    # FIX: No inplace=True\n",
    "    if df_processed['size_purchased'].notna().any():\n",
    "        most_common_size = df_processed['size_purchased'].mode()[0]\n",
    "        df_processed['size_purchased'] = df_processed['size_purchased'].fillna(most_common_size)\n",
    "        le_size = LabelEncoder()\n",
    "        df_processed['size_encoded'] = le_size.fit_transform(df_processed['size_purchased'])\n",
    "\n",
    "    feature_cols = [\n",
    "        'customer_age', 'customer_tenure_days', 'product_category_encoded',\n",
    "        'product_price', 'days_since_last_purchase', 'previous_returns',\n",
    "        'product_rating', 'size_encoded', 'discount_applied'\n",
    "    ]\n",
    "    return df_processed[feature_cols], df_processed['is_return']\n",
    "\n",
    "def calculate_financials(y_true, y_prob, threshold):\n",
    "    y_pred = (y_prob >= threshold).astype(int)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "\n",
    "    # Constants\n",
    "    COST_RETURN = 18.0\n",
    "    COST_INTERVENTION = 3.0\n",
    "    SUCCESS_RATE = 0.35\n",
    "\n",
    "    # 1. Baseline Cost (No Model)\n",
    "    # We pay $18 for every actual return\n",
    "    baseline_cost = (tp + fn) * COST_RETURN\n",
    "\n",
    "    # 2. Model Cost\n",
    "    # Intervention Cost: We pay $3 for every flagged order (TP + FP)\n",
    "    intervention_spend = (tp + fp) * COST_INTERVENTION\n",
    "\n",
    "    # Remaining Return Cost:\n",
    "    # - We pay full $18 for missed returns (FN)\n",
    "    # - We pay full $18 for the 65% of caught returns (TP) that didn't convert\n",
    "    unprevented_returns_cost = (fn * COST_RETURN) + (tp * (1 - SUCCESS_RATE) * COST_RETURN)\n",
    "\n",
    "    total_model_cost = intervention_spend + unprevented_returns_cost\n",
    "\n",
    "    # 3. Metrics\n",
    "    net_savings = baseline_cost - total_model_cost\n",
    "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "\n",
    "    return {\n",
    "        \"Threshold\": threshold,\n",
    "        \"Net_Savings\": net_savings,\n",
    "        \"Precision\": precision,\n",
    "        \"Recall\": recall,\n",
    "        \"Interventions\": tp + fp,\n",
    "        \"TP\": tp,\n",
    "        \"FP\": fp\n",
    "    }"
   ],
   "id": "f079cfb15468dba",
   "outputs": [],
   "execution_count": 44
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-21T01:02:44.634954Z",
     "start_time": "2025-11-21T01:02:44.613522Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X_train, y_train = preprocess_fixed(train)\n",
    "X_test, y_test = preprocess_fixed(test)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "model = LogisticRegression(random_state=42, max_iter=1000)\n",
    "model.fit(X_train_scaled, y_train)\n",
    "y_probs = model.predict_proba(X_test_scaled)[:, 1]\n"
   ],
   "id": "137c5d1811712b7c",
   "outputs": [],
   "execution_count": 43
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-21T01:03:20.773274Z",
     "start_time": "2025-11-21T01:03:20.706712Z"
    }
   },
   "cell_type": "code",
   "source": [
    "results = []\n",
    "thresholds = np.arange(0.05, 0.95, 0.01)\n",
    "\n",
    "for t in thresholds:\n",
    "    results.append(calculate_financials(y_test, y_probs, t))\n",
    "\n",
    "df_results = pd.DataFrame(results)\n",
    "\n",
    "# Find Optimal\n",
    "best_run = df_results.loc[df_results['Net_Savings'].idxmax()]\n",
    "\n",
    "print(\"=== FINANCIAL ANALYSIS RESULTS ===\")\n",
    "print(f\"Optimal Threshold: {best_run['Threshold']:.2f}\")\n",
    "print(f\"Max Net Savings:   ${best_run['Net_Savings']:.2f}\")\n",
    "print(f\"Precision at Opt:  {best_run['Precision']:.2%}\")\n",
    "print(f\"Recall at Opt:     {best_run['Recall']:.2%}\")\n",
    "print(f\"Interventions:     {int(best_run['Interventions'])}\")\n",
    "print(\"-\" * 30)\n",
    "print(\"Breakeven Precision Required: ~47.6%\")"
   ],
   "id": "a1e07fdf3918277",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== FINANCIAL ANALYSIS RESULTS ===\n",
      "Optimal Threshold: 0.40\n",
      "Max Net Savings:   $0.00\n",
      "Precision at Opt:  0.00%\n",
      "Recall at Opt:     0.00%\n",
      "Interventions:     0\n",
      "------------------------------\n",
      "Breakeven Precision Required: ~47.6%\n"
     ]
    }
   ],
   "execution_count": 45
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-21T01:03:47.913362Z",
     "start_time": "2025-11-21T01:03:47.911048Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Check if we ever make money\n",
    "if best_run['Net_Savings'] <= 0:\n",
    "    print(\"\\nThe model NEVER makes a profit.\")\n",
    "    print(\"Reason: The model cannot isolate a segment of users with >47.6% return probability.\")\n",
    "else:\n",
    "    print(\"\\nThe model found a profitable pocket of customers.\")"
   ],
   "id": "15701e0638570890",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The model NEVER makes a profit.\n",
      "Reason: The model cannot isolate a segment of users with >47.6% return probability.\n"
     ]
    }
   ],
   "execution_count": 47
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "3. The Breakeven Point:\n",
    "- To break even, we need  Precision×($18×0.35)>$3.00\n",
    "- The model must be at least 47.6% precise.\n",
    "- The baseline Logistic Regression likely never reaches this precision on the test set because the features are too weak (ROC-AUC ~0.56). T it cannot find any group of customers\n",
    "4. Threshold Selection Rationale: The selection of 0.40 is essentially arbitrary in this specific context, it simply represents a \"cutoff\" high enough that no orders crossed it.\n",
    "- If we lowered the threshold to 0.25: We would catch some returns (High Recall), but we would flag so many non-returners (Low Precision) that the intervention costs would skyrocket, leading to negative savings.\n",
    "- To technically determine the optimal threshold for selection, a process called Profit Curve Optimization (or Cost-Sensitive Learning). Using TP, FP for Breakeven Ratio 3.30×P(TP)>3.00×P(FP).\n",
    "Benefit of a True Positive (TP):\n",
    "Identify a return correctly, intervene (3 cost), save the return 35% of the time (18 saving). Net Value: (18×0.35)−3=+3.30\n",
    "Cost of a False Positive (FP):\n",
    "Flag a loyal customer who wasn't going to return anyway, intervene (3 cost), no savings occur. Net Value: −3.\n",
    "The Breakeven Ratio: To make money, the expected value must be positive 3.30×P(TP)>3.00×P(FP). This implies the need roughly 1 TP for every 1 FP.\n",
    "5. A \"Good Enough to Deploy\" Criteria: This model is NOT good enough to deploy. To justify deployment, a future iteration must\n",
    "- Push Probabilities Higher: We need a model that outputs probabilities > 50% for specific high-risk segments (\"Young customers buying XXL Fashion items on discount\").\n",
    "- Achieve Positive ROI: We need to see Net Savings > $0.\n",
    "\n",
    "\n",
    "What's the optimal balance between catching returns (recall) and avoiding wasted interventions (precision)?\n",
    "- In this specific financial scenario, Precision is significantly more important than Recall. It must prioritize avoiding wasted interventions over catching every return. The optimal balance requires a \"Sniper\" strategy (High Precision / Lower Recall), rather than a \"Shotgun\" strategy.\n",
    "- Low Precision / High Recall: Bankrupts the program (Wasted intervention costs exceed savings).\n",
    "- High Precision / Low Recall: Profitable but small scale (Positive ROI, but leaves money on the table by missing returns)."
   ],
   "id": "b16be1915cf3c94a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "6a3d89807e0ab03d"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
